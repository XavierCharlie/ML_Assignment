{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bank Marketing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The  data is related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be ('yes') or not ('no') subscribed.  \n",
    "\n",
    "We chose this dataset because its big enough, so when we split it into train, validation and test, these subsets will be relatively big for our algorithms to learn well increasing their accuracy and reliability also because Marketing is a very crucial part of every business, so knowing how to win a customer sounded very interesting to us since we are anticipating on changing the world in the business field in future.\n",
    "\n",
    "## Dataset Overview\n",
    "### The Dataset has 20 Input Variables  (Features):\n",
    "\n",
    "**#bank client data:**  \n",
    "1 - _Age_ (numeric)  \n",
    "2 - _Job_ **:** type of job (categorical: 'admin.', 'blue-collar', 'entrepreneur', 'housemaid', 'management', 'retired', 'self-employed', 'services', 'student', 'technician', 'unemployed', 'unknown')  \n",
    "3 - _Marital_ **:** marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)  \n",
    "4 - _Education_ (categorical:   'basic.4y', 'basic.6y', 'basic.9y', 'high.school', 'illiterate', 'professional.course', 'university.degree', 'unknown')  \n",
    "5 - _Default_ **:** has credit in default? (categorical: 'no', 'yes', 'unknown')\n",
    "6 - _Housing_ **:** has housing loan? (categorical: 'no', 'yes', 'unknown')  \n",
    "7 - _Loan_ **:** has personal loan? (categorical: 'no', 'yes', 'unknown')  \n",
    "\n",
    "**#related with the last contact of the current campaign:**  \n",
    "8 - _Contact_ **:** contact communication type (categorical: 'cellular', 'telephone')  \n",
    "9 - _Month_ **:** last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')  \n",
    "10 - _Day_of_week_ **:** last contact day of the week (categorical: 'mon', 'tue', 'wed', 'thu', 'fri')  \n",
    "11 - _Duration_ **:** last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.  \n",
    "\n",
    "**#other attributes:**  \n",
    "12 - _Campaign_ **:** number of contacts performed during this campaign and for this client (numeric, includes last contact)  \n",
    "13 - _pDays_ **:** number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)  \n",
    "14 - _Previous_ **:** number of contacts performed before this campaign and for this client (numeric)  \n",
    "15 - _pOutcome_ **:** outcome of the previous marketing campaign (categorical: 'failure', 'nonexistent', 'success')  \n",
    "\n",
    "**#social and economic context attributes**  \n",
    "16 - _emp.var.rate_ **:** employment variation rate - quarterly indicator (numeric)  \n",
    "17 - _cons.price.idx_ **:** consumer price index - monthly indicator (numeric)  \n",
    "18 - _cons.conf.idx_ **:** consumer confidence index - monthly indicator (numeric)  \n",
    "19 - _Euribor3m_ **:** euribor 3 month rate - daily indicator (numeric)  \n",
    "20 - _nr.employed_ **:** number of employees - quarterly indicator (numeric)  \n",
    "\n",
    "### Output Variable (Desired Target):\n",
    "y - has the client subscribed a term deposit? (binary: 'yes', 'no')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contributors:\n",
    "* Phillip Moyo – 2185695   \n",
    "* Moshito Charles Makgakga – 1445435   \n",
    "* Godfrey T Chamunogwa – 2234379\n",
    "* Fankholoro Vincent Sebothoma – 1671848   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah Blah "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder,MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('bank-full.csv', sep=\";\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trimming the Data\n",
    "The Data is heavily biased, so we are trimming it to make the different output classes more even (unbiased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_yes = df[df['y']=='yes']\n",
    "df_no = df[df['y']=='no']\n",
    "df_no = df_no.iloc[:5289, :]\n",
    "\n",
    "df = pd.concat([df_yes, df_no])\n",
    "df = df.sample(frac=1).reset_index(drop=True)       #shuffle the rows\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##--scaling column(y)=> 'yes'=1 and 'no'=0 also @there are no null values in our dataset---##\n",
    "y = LabelEncoder()\n",
    "df.iloc[:,-1] = y.fit_transform(df.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##--scaling column(poutcome)=> 'failure'=0, 'other'=1, 'success'=2, 'unknown'=3\n",
    "poutcome = LabelEncoder()\n",
    "df.iloc[:,-2] = poutcome.fit_transform(df.iloc[:,-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##--scaling column(contact)=> 'cellular'=0, 'telephone'=1, 'unknown'=2\n",
    "contact = LabelEncoder()\n",
    "df.iloc[:,8] = contact.fit_transform(df.iloc[:,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##--scaling column(marital)=> 'married'=1, 'divorced'=0, 'single'=2\n",
    "marital = LabelEncoder()\n",
    "df.iloc[:,2] = marital.fit_transform(df.iloc[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##--scaling column(education)=> 'primary'=0, 'secondary'=1, 'tertiary'=2, 'unknown'=3\n",
    "education = LabelEncoder()\n",
    "df.iloc[:,3] = education.fit_transform(df.iloc[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##--scaling column(default)=> 'yes'=1, 'no'=0'\n",
    "default = LabelEncoder()\n",
    "df.iloc[:,4] = default.fit_transform(df.iloc[:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##--scaling column(housing)=> 'yes'=1, 'no'=0'\n",
    "housing = LabelEncoder()\n",
    "df.iloc[:,6] = housing.fit_transform(df.iloc[:,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##--scaling column(loan)=> 'yes'=1, 'no'=0'\n",
    "loan = LabelEncoder()\n",
    "df.iloc[:,7] = loan.fit_transform(df.iloc[:,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##--scaling column(month)=> 'jan'=1,'feb'=2, 'mar'=3,...,'dec'=12\n",
    "month = df.iloc[:,10].replace(['jan','feb','mar','apr','may','jun','jul','aug','sep','oct','nov','dec'],[1,2,3,4,5,6,7,8,9,10,11,12])\n",
    "df.iloc[:,10] = month "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##--scaling column(job)\n",
    "job = df.iloc[:,1].replace(['blue-collar', 'admin.', 'technician', 'management', 'retired','student', 'entrepreneur', 'services', 'self-employed','unemployed', 'housemaid', 'unknown'],[1,2,3,4,5,6,7,8,9,10,11,12])\n",
    "df.iloc[:,1] = job "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add bias column of 1's\n",
    "df.insert(0, 'bias', np.ones(df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## scale the features\n",
    "scaler = MinMaxScaler()\n",
    "columns = ['age', 'job', 'marital', 'education', 'default', 'balance', 'housing', 'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays', 'previous', 'poutcome'] \n",
    "df[columns] = scaler.fit_transform(df[columns])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the Dataset into Training, Validation and Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training data (60% of the data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trining dataset\n",
    "train_data = df.iloc[:6347:]\n",
    "\n",
    "# training features\n",
    "train_features = train_data.iloc[:,:-1].values\n",
    "\n",
    "# training targets\n",
    "train_targets = train_data.iloc[:,-1].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation data (20% of the data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation dataset\n",
    "validate_data = df.iloc[6347:8463:]\n",
    "\n",
    "# validation features\n",
    "validate_features = validate_data.iloc[:,:-1].values\n",
    "\n",
    "# validation targets\n",
    "validate_targets = validate_data.iloc[:,-1].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing data (20% of the data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing dataset\n",
    "test_data = df.iloc[8463::]\n",
    "\n",
    "# testing features\n",
    "test_features = test_data.iloc[:,:-1].values\n",
    "\n",
    "# testing targets\n",
    "test_targets = test_data.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Logistic Regression Model on the Training Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial weights and they include the intercept (bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial weights are\n",
    "params = params = np.random.uniform(-1, 1, train_features.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularizer(params , lambda_):\n",
    "    p = np.array([])\n",
    "    y = params[:1:]\n",
    "    z = params[1:len(params):]*lambda_\n",
    "    p = np.append(p,y)\n",
    "    p = np.append(p,z)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function that does gradient desent with regularisation or not\n",
    "def GD(qnew, design_matrix, y_values, alpha, epsalon, lambda_, boolean):\n",
    "    i = 0\n",
    "    qold = np.zeros(len(qnew))\n",
    "    hx = 1/(1 + np.exp(-(design_matrix @ qnew)))\n",
    "    \n",
    "    # regularization must occour\n",
    "    if(boolean):\n",
    "        while (np.linalg.norm(qnew - qold,2) > epsalon) and (i != 1000) :\n",
    "            i = i + 1\n",
    "            qold = qnew\n",
    "            hx = 1/(1 + np.exp(-(qnew @ design_matrix.T)))\n",
    "            qnew = qold - alpha*(((hx - y_values) @ design_matrix) + regularizer(qold , lambda_))\n",
    "        \n",
    "        return qnew\n",
    "    \n",
    "    # no regularisation is required\n",
    "    else:\n",
    "        while (np.linalg.norm(qnew - qold,2) > epsalon) and (i != 10000):\n",
    "            i = i + 1\n",
    "            qold = qnew\n",
    "            hx = 1/(1 + np.exp(-(design_matrix @ qnew)))\n",
    "            qnew = qold - alpha*(((hx - y_values) @ design_matrix) )\n",
    "        \n",
    "        return qnew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsalon = 0.000001\n",
    "lambda_ = 0.01\n",
    "alpha = 0.001\n",
    "optimal_params = GD(params,train_features, train_targets, alpha,epsalon, lambda_, True )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the Test Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_test = 1/(1 + np.exp(-(test_features @ optimal_params)))\n",
    "print(predicted_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the Accuracy of the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hxx = 1/(1 + np.exp(-(train_features @ optimal_params)))\n",
    "train_error = -((train_targets @ np.log(hxx) +  (1 - train_targets) @ np.log(1 - hxx)))\n",
    "print(train_error)\n",
    "               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error on the testng data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hxy = 1/(1 + np.exp(-(test_features @ params)))\n",
    "test_error = -((test_targets @ np.log(hxy) +  (1 - test_targets) @ np.log(1 - hxy)))\n",
    "print(test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the confusion matrix for the model\n",
    "class_0_0 = 0 # in class 0 and classified in class 0\n",
    "class_0_1 = 0 # in class 0 and classified in class 1\n",
    "class_1_0 = 0 # in class 1 and classified in class 0\n",
    "class_1_1 = 0 # in class 1 and classified in class 1\n",
    "predicted = np.round(predicted_test)\n",
    "for i in range(len(hxy)):\n",
    "    if(predicted[i] == 0 and test_targets[i] == 0):\n",
    "        ++class_0_0\n",
    "    if(predicted[i] == 0 and test_targets[i] == 0):\n",
    "        class_0_0 += 1\n",
    "        \n",
    "    elif (predicted[i] == 0 and test_targets[i] == 1):\n",
    "        class_0_1 += 1\n",
    "        \n",
    "    elif (predicted[i] == 1 and test_targets[i] == 0):\n",
    "        class_1_0 += 1\n",
    "        \n",
    "    elif (predicted[i] == 1 and test_targets[i] == 1):\n",
    "        class_1_1 += 1\n",
    "    else:\n",
    "        print(\"i couldint classify: \", y_predicted)\n",
    "        \n",
    "print('       confusion Matrix        ')\n",
    "print('-------------------------------')\n",
    "print('%-s %-7s %-s %-5s %-s %-5s %-s' %('|',' ','|','class 0','|','class 1','|',))\n",
    "print('-------------------------------')\n",
    "print('%-s %-5s %-s %-7i %-s %-7i %-s' %('|','class 0','|',class_0_0,'|',class_0_1,'|'))\n",
    "print('-------------------------------')\n",
    "print('%-s %-5s %-s %-7i %-s %-7i %-s' %('|','class 1','|',class_1_0,'|',class_1_1,'|'))\n",
    "print('-------------------------------')\n",
    "accuracy = ((class_0_0 + class_1_1) / (class_0_0 + class_0_1 + class_1_0 + class_1_1)) * 100\n",
    "print('Your model is', accuracy,'%', 'acurate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Set Results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(test_features[:,4], test_targets, c = 'yellow')\n",
    "# plt.scatter(combined_class[20:,0], combined_class[20:,1], c = 'blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
